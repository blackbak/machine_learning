{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Text 3-class classification/sentiment analysis of twitter data using RnnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gensim\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from rnn_utils import RnnClassifier, pre_processX, pre_processY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to encode words into vectors to feed to the classifier we use a pre-trained word2vec model from Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Methods in order to parse words and a list of word2vec vectors\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(path_to_w2v_bin, binary=True)  \n",
    "###Function accepts a list of strings and returns a list of vectors for words that exist in the vocabulary\n",
    "def w2v_parse(list_of_strings):\n",
    "    w2v_list = []\n",
    "    for text in list_of_strings:\n",
    "        tokens = text.split()\n",
    "        w2v_item_list = []\n",
    "        for word in tokens:\n",
    "            try:\n",
    "                w2v_item_list.append(w2v_model.word_vec(word))\n",
    "            except:\n",
    "                continue\n",
    "        w2v_list.append(w2v_item_list)\n",
    "    return w2v_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset consists of a set of tweets that have been scored 0 for neutral, 1 for positive sentiment and -1 for negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@AppIeGivevvay if your not affiliated how the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@gay_emo_zac haha... I wouldn't be surprised.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@SteamPowered damn, so many good deals...you g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>i m totally confused and bored.. my life must ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@DWStweets @Kazport Good luck with that. You h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                               text\n",
       "0         0  @AppIeGivevvay if your not affiliated how the ...\n",
       "1         0  @gay_emo_zac haha... I wouldn't be surprised.....\n",
       "2         0  @SteamPowered damn, so many good deals...you g...\n",
       "3        -1  i m totally confused and bored.. my life must ...\n",
       "4         0  @DWStweets @Kazport Good luck with that. You h..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Get twitter data with positive-neutral-negative sentiment\n",
    "twitter = pd.read_csv(path_to_file)\n",
    "twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Basic text curation to remove handles and other useless stuff\n",
    "twitter_list = [' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x).split()) for x in twitter[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###one-hot encoding\n",
    "twitter_labels = np.zeros([len(twitter), 3])\n",
    "twitter_labels[np.arange(len(twitter)), twitter.polarity] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Shuffling and getting train and test/validation set\n",
    "twitter_list, twitter_labels = shuffle(twitter_list, twitter_labels)\n",
    "splt = int(0.8*len(twitter_list))\n",
    "train_labels = twitter_labels[:splt]\n",
    "train_text = twitter_list[:splt]\n",
    "test_labels = twitter_labels[splt:]\n",
    "test_text = twitter_list[splt:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###From list of words to list of vectors\n",
    "train_input = w2v_parse(train_text)\n",
    "test_input = w2v_parse(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Make input np.array(Sample_size, Max_sequence_length, Embedding_dimension) with zero padding and get length of each sequence\n",
    "train_input, train_len = pre_processX(train_input)\n",
    "test_input, test_len = pre_processX(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this point we are readdy to use RnnClassifier. The class works as any other model taken from sklearn library with functions such as .train and .predict. Also the feed forward part is customizable upon creation with the output_architecture variable. The log for the tensorboard visualization are stored at the tensorboard_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 of epoch 0 has accuracy: [0.39500001]\n",
      "Step 5 of epoch 0 has accuracy: [0.34]\n",
      "Step 10 of epoch 0 has accuracy: [0.44499999]\n",
      "Step 15 of epoch 0 has accuracy: [0.47499999]\n",
      "Step 20 of epoch 0 has accuracy: [0.58999997]\n",
      "Step 25 of epoch 0 has accuracy: [0.60500002]\n",
      "Step 30 of epoch 0 has accuracy: [0.63499999]\n",
      "Step 35 of epoch 0 has accuracy: [0.56999999]\n",
      "Step 40 of epoch 0 has accuracy: [0.57499999]\n",
      "Step 45 of epoch 0 has accuracy: [0.61000001]\n",
      "Step 50 of epoch 0 has accuracy: [0.63999999]\n",
      "Step 55 of epoch 0 has accuracy: [0.70499998]\n",
      "Step 60 of epoch 0 has accuracy: [0.61000001]\n",
      "Step 65 of epoch 0 has accuracy: [0.57999998]\n",
      "Step 70 of epoch 0 has accuracy: [0.65499997]\n",
      "Step 75 of epoch 0 has accuracy: [0.63999999]\n",
      "Step 80 of epoch 0 has accuracy: [0.63999999]\n",
      "Step 85 of epoch 0 has accuracy: [0.63]\n",
      "Step 90 of epoch 0 has accuracy: [0.64999998]\n",
      "Step 95 of epoch 0 has accuracy: [0.69499999]\n",
      "Step 100 of epoch 0 has accuracy: [0.59500003]\n",
      "Step 105 of epoch 0 has accuracy: [0.67000002]\n",
      "Step 110 of epoch 0 has accuracy: [0.61500001]\n",
      "Step 115 of epoch 0 has accuracy: [0.60500002]\n",
      "Step 120 of epoch 0 has accuracy: [0.61500001]\n",
      "Step 125 of epoch 0 has accuracy: [0.69999999]\n",
      "Step 130 of epoch 0 has accuracy: [0.65499997]\n",
      "Step 135 of epoch 0 has accuracy: [0.62]\n",
      "Step 140 of epoch 0 has accuracy: [0.67000002]\n",
      "Step 145 of epoch 0 has accuracy: [0.66500002]\n",
      "Step 150 of epoch 0 has accuracy: [0.65499997]\n",
      "Step 155 of epoch 0 has accuracy: [0.565]\n",
      "Step 160 of epoch 0 has accuracy: [0.66500002]\n",
      "Step 165 of epoch 0 has accuracy: [0.55500001]\n",
      "Epoch 0 has cost: 0.865686004361\n",
      "Step 0 of epoch 1 has accuracy: [0.69]\n",
      "Step 5 of epoch 1 has accuracy: [0.685]\n",
      "Step 10 of epoch 1 has accuracy: [0.72000003]\n",
      "Step 15 of epoch 1 has accuracy: [0.66000003]\n",
      "Step 20 of epoch 1 has accuracy: [0.63]\n",
      "Step 25 of epoch 1 has accuracy: [0.63999999]\n",
      "Step 30 of epoch 1 has accuracy: [0.67000002]\n",
      "Step 35 of epoch 1 has accuracy: [0.62]\n",
      "Step 40 of epoch 1 has accuracy: [0.69]\n",
      "Step 45 of epoch 1 has accuracy: [0.67000002]\n",
      "Step 50 of epoch 1 has accuracy: [0.75]\n",
      "Step 55 of epoch 1 has accuracy: [0.64499998]\n",
      "Step 60 of epoch 1 has accuracy: [0.72000003]\n",
      "Step 65 of epoch 1 has accuracy: [0.71499997]\n",
      "Step 70 of epoch 1 has accuracy: [0.625]\n",
      "Step 75 of epoch 1 has accuracy: [0.69499999]\n",
      "Step 80 of epoch 1 has accuracy: [0.67000002]\n",
      "Step 85 of epoch 1 has accuracy: [0.69999999]\n",
      "Step 90 of epoch 1 has accuracy: [0.74000001]\n",
      "Step 95 of epoch 1 has accuracy: [0.63499999]\n",
      "Step 100 of epoch 1 has accuracy: [0.63999999]\n",
      "Step 105 of epoch 1 has accuracy: [0.69999999]\n",
      "Step 110 of epoch 1 has accuracy: [0.71499997]\n",
      "Step 115 of epoch 1 has accuracy: [0.71499997]\n",
      "Step 120 of epoch 1 has accuracy: [0.74000001]\n",
      "Step 125 of epoch 1 has accuracy: [0.70999998]\n",
      "Step 130 of epoch 1 has accuracy: [0.73500001]\n",
      "Step 135 of epoch 1 has accuracy: [0.66500002]\n",
      "Step 140 of epoch 1 has accuracy: [0.64499998]\n",
      "Step 145 of epoch 1 has accuracy: [0.61000001]\n",
      "Step 150 of epoch 1 has accuracy: [0.63]\n",
      "Step 155 of epoch 1 has accuracy: [0.64999998]\n",
      "Step 160 of epoch 1 has accuracy: [0.625]\n",
      "Step 165 of epoch 1 has accuracy: [0.65499997]\n",
      "Epoch 1 has cost: 0.785424097308\n"
     ]
    }
   ],
   "source": [
    "model = RnnClassifier(n_classes=3, embedding_dimension=300, output_architecture=[500], \n",
    "                      tensorboard_dir=\"./tensorboard_logs/\", batch_size=200)\n",
    "model.train(train_input, train_labels, train_len, epochs=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655\n"
     ]
    }
   ],
   "source": [
    "###Get test set accuracy\n",
    "twitter_preds = model.predict(test_input, test_len)\n",
    "print(accuracy_score(twitter_preds.argmax(axis=1), test_labels.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m tensorflow.tensorboard --logdir=tensorboard_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now point to the specified url and port to view the visualizations of the tensorflow graph and the statistics of the variables during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.destruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
